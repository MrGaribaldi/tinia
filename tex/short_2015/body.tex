% ---------------------------------------------------------------------
% EG author guidelines plus sample file for EG publication using LaTeX2e input
% D.Fellner, v1.17, Sep 23, 2010


\title[Automatic Proxy Geometry]%
      {Automatic Proxy Geometry}

% for anonymous conference submission please enter your SUBMISSION ID
% instead of the author's name (and leave the affiliation blank) !!
\author[J.\,O. Nygaard \& J. Mikkelsen]
       {J.\,O. Nygaard$^{1}$
        and J. Mikkelsen$^{1}$
        and Husk Anonymisering Hvis Paakrevet!$^{1}$
%        S. Spencer$^2$\thanks{Chairman Siggraph Publications Board}
        \\
% For Computer Graphics Forum: Please use the abbreviation of your first name.
         $^1$SINTEF ICT, applied mathematics, Norway
%        $^2$ Another Department to illustrate the use in papers from authors
%             with different affiliations
       }

% ------------------------------------------------------------------------

% if the Editors-in-Chief have given you the data, you may uncomment
% the following five lines and insert it here
%
% \volume{27}   % the volume in which the issue will be published;
% \issue{1}     % the issue number of the publication
% \pStartPage{1}      % set starting page


%-------------------------------------------------------------------------
\begin{document}

% \teaser{
%  \includegraphics[width=\linewidth]{eg_new}
%  \centering
%   \caption{New EG Logo}
% \label{fig:teaser}
% }

\maketitle

\begin{abstract}
   We describe an algorithm and implementation of an automatic proxy geometry
   system for a server/client remote rendering setup. The client may be a thin
   client in the form of a hand-held pad, for our implementation we only assume
   the availability of WebGL and Javascript. For our rendering server, we make
   use of a GL-capable web server. In situations where the rate of received
   images deteriorate due to low bandwith, high latency or long rendering times,
   the client displays an automatically generated proxy geometry. This proxy
   geometry is computed from depth buffers bundled with rendered images from the
   server, and requires no modification of the application or its data itself.
   % Husk: Skal vaere en blank linje nedenfor

\begin{classification} % according to http://www.acm.org/class/1998/
\CCScat{FIX THIS Computer Graphics}{I.3.3}{Picture/Image Generation}{Line and curve generation}
\end{classification}

\end{abstract}




%-------------------------------------------------------------------------
\section{Introduction}

\begin{figure}[htb]
  \centering
  \subfigure[Server-rendered (OpenGL)]{
    \includegraphics[width=.47\linewidth]{frview1.jpg}
  }
  \subfigure[Client-rendered proxy model (Google Chrome)]{
    \includegraphics[width=.47\linewidth]{frview2.jpg}
  }
  \caption{\label{fig:FRView} The oil reservoir viewer FRView, showing a
  server-rendered image and a proxy geometry generated from this and the
  accompanying depth buffer. Note that we have chosen parameters for the proxy
  generation (small number of splats ($128^2$), forcing display of splats that
  would normally be discarded) to emphasize rather than reduce artifacts, \eg,
  the ragged edges, a few holes, and the oddly placed (and rendered) axis
  indicator.}
\end{figure}

With increasingly powerful rendering engines, in forms ranging from mobile and
hand-held devices to traditional stationary computers, one might be led to
believe that rendering frame rates could only increase and visualization could
only become more interactive. Alas, hand in hand with this development we also
find ever increasing requirements on computational accuracy, power efficiency,
data sizes, scaling, etc.

One effect of this, also enhanced by new cloud-based approaches, wireless
connection, and mobile devices with display capabilities outpacing their
computation and storage capabilities, is that interactivity still is a difficult
issue. In this work, we consider a server/client model for rendering, but this
is just a way of separating the interaction from the rendering; the discussion
also applies to a more integrated setup.  In order to obtain the frame rates on
the client suitable for interactive visualizations, demands are put on
bandwidth, latency and rendering speed. If one or more of these demands are not
met, according to a suitable measure, the frame rate will deteriorate together
with the user experience.

One way to deal with such situations is for the client to have a {\em
proxy model}, defined as a temporary model to be shown and manipulated
locally on the client while waiting for the appropriate image from the server.
A particularly unwelcomed chore is that of building proxy geometries for various
data sets. The typical ``hello world'' proxy geometry is the familiar bounding
box wire frame, but this will degrade the user experience unacceptably for most
applications. One alternative is to hand craft such simpler proxies. They have
to be simple both for the building cost, and also for the actual rendering on
the possibly very thin client. Another alternative is to automate this process,
a large triangulation may for instance be represented by a much coarser
approximating triangulation that can be built automatically. One disadvantage of
this approach is that this is not easy to do for many kinds of data, like our
main case in which we have an oil reservoir viewer (FRView) that renders large
{\em corner points grids}, together with {\em faults}, oil wells, and more. See
Figure~\ref{fig:FRView} above for an example of both a fully completed
rendering, and an automatically generated proxy geometry rendered in Google
Chrome.

Our suggested solution is to pass depth information from the server along with
ordinary rendered images. From this depth image, a rudimentary 3D model can be
built, and using the ordinary image as a texture, this model can be transformed
and rendered on the client while waiting for the next update from the server. If
the server does not take too long to respond, and/or the client does not change
the position or orientation of the model too much, this display of a proxy model
integrates seemlessly with the slower stream of server-rendered frames.

We also mention that even if bandwidth and latency is not a problem, it may be
desirable to let a server of limited capacity serve many simultaneous users,
hence decreasing the effective server time available for each one. In this case,
suitable scaling properties may still be achieved without increasing server
capacity. \textbf{referanse til ArrowHead her?}

\subsection{Previous work}

Our approach has some similarities to {\em image based rendering} (IBR)
techniques (\textbf{referanse til noe av dette?}), with the difference that an
important IBR problem would be the reconstruction of a depth map from images,
while we have access to the full depth map from a rendering pass.
Another way to use depth maps similar to what we do, is for ``immersive
streaming'',
see \eg, \texttt{http://www.cc...},
% http://www.cc.gatech.edu/conferences/3DPVT08/Program/Papers/paper203.pdf
where focus is on depth map compression, an issue that we also must confront.

We are not aware of anybody else using depth maps exactly for our purpose, most
research seems to be focused on the retrieval of the depth map from images,
while we use an existing depth map to distill and render temporary geometry.



%-------------------------------------------------------------------------

\section{The auto proxy algorithm}

The main idea is to automatically construct a proxy geometry on the client side
from depth data provided by the server. For a new image to be displayed on the
client, the server renders an image in a frame buffer, and as part of this
process it also renders a corresponding depth buffer. (This means that our
technique is not immediately ready for \eg, ray-tracing.) This depth buffer may
be regarded as a height map over a viewing plane relative to the observing
client. Hence, this depth map does not contain information about scene elements
not in view for the set of view parameters at the time of server side
rendering. Our approach is based on the assumption that small transformations of
this height map still will give good approximations to the scene being
rendered. These renderings are exactly what the client will compute and show
while waiting for the next update from the server. See
Figure~\ref{fig:2Dheightmap} and Figure~\ref{fig:2DheightmapRotated} below for an
illustration of this heightmap computed on the server, and a recovered 3D model
on the client.

\begin{figure}[htb]
  \centering
  \input{fig2.tex}

  \caption{\label{fig:2Dheightmap} The rendered image (of \eg, a cube) as a
           height map seen from above, for a certain transformation. Also shown
           are the corresponding RGB-fragments (red and green) and depth
           fragments (floating point scalars shown as grayscale pixels.)}
\end{figure}

In Figure~\ref{fig:2DheightmapRotated} below, a sequence of three server-rendered
images (solid lines, red and blue) is shown, together with intermediate
client-rendered proxy models with different features. These features will be
discussed later, in Section~\ref{sec:client}.

\begin{figure}[htb]
  \centering
  \subfigure[Low frame rate]{
    \input{fig3a.tex}
  }
  \subfigure[Initial proxy model]{
    \input{fig3b.tex}
  }
  \subfigure[Client-generated frame]{
    \input{fig3c.tex}
  }
  \subfigure[With texturing]{
    \input{fig3d.tex}
  }
  \subfigure[Screen-space-sized splats]{
    \input{fig3e.tex}
  }
  \subfigure[With intra-splat depths]{
    \input{fig3f.tex}
  }
  \caption{\label{fig:2DheightmapRotated}
           The depth map and image sent from the server enables the client to
           recover a 3D model approximating the one rendered on the server. This
           client-side model is shown here with a small additional rotation, again
           seen from above.}
\end{figure}

Note that the depth map from the server does not allow the client to recover all
information in the server side model. For instance, the solid surface shown in
Figure~\ref{fig:2Dheightmap} (\ie, the {\em topology}) cannot be deduced, hence
we show the dots in Figure~\ref{fig:2DheightmapRotated}~(b). Still, there are
several things we can do to improve the client's approximation of
the server-side image, and these will now be described.


%-------------------------------------------------------------------------
\subsection{The server}

The server keeps a 3D model and accompanying viewing parameters, and will render
an image for delivery to the client either on its own accord or because the
client requests it. As long as the server renders a picture into a framebuffer
with a connected depth buffer, it has a negligible cost for the server to bundle
the resulting depth map with the rendered image upon return of the result. In
practice, this is easily handled by a few extra lines of computer code where the
image is extracted from its framebuffer and prepared for sending to the
client.

Since the depth buffer adds somewhat to the data being sent, it is important to
keep it to a minimum. We have found that reducing the spatial resolution of the
depth buffer (for instance by a factor of $1/16$) only to a negligible extent
degrades the proxy model being reconstructed by the client. We encode each depth
value in the range $[0, 1]$ as a 16 bit fixed point number, this also works
quite well. These measures cause the bundling of the depth buffer with the rgb
image to impose just a small data overhead.

Further compression methods (\textbf{passende med en ref her?}) may be employed
to bring this data size down even more, but then the cost of the compression
itself must also be added to the cost of rendering on the server.
%
%The cost must of course be considered if the operation of packaging images for
%sending to the client is significant, which may be the case if, \eg, images must
%be compressed or converted to some special format. An example of the latter
%might be {\texttt base64}-encoding for converting the image to a purely ASCII
%format.
%
Together with the rendered rgb image and the depth image we will also send the
current view transformations back to the client.


%-------------------------------------------------------------------------
\subsection{The client}
\label{sec:client}

When the client receieves an rgb and depth image, together with view
transformations, it builds a ``proxy model'' from this. This model can then be
transformed and rendered directly if there is no available image from the
server, or it can be combined with other proxy models the client already has in
store. The latter option will be discussed in
Section~\ref{sec:proxyModelReplacement}.


%-------------------------------------------------------------------------
\subsubsection{Proxy model building, splats}

As indicated by Figure~\ref{fig:2DheightmapRotated}~(b), the received
height map does not really allow us more than concluding where a set of points
belong to the 3D model, these points giving rise to exactly the depth map from
the server. Given these points, the client may build a model approximating the
actual scene being rendered on the server. Since the information from such a
depth map can only contain the foremost point along any ray from the observer
toward the scene, it is often said to be in 2.5D, as opposed to purely 2D or
fully 3D.

The most simple thing the client can do, is just to transform and render this
set of 3D points with the color sampled from the corresponding location in the
server-rendered image, this is illustrated in
Figure~\ref{fig:2DheightmapRotated}~(b).

It makes sense for the client only to render at most one 3D point for each depth
fragment available. This may be too much for a thin client, and one may want to
operate with a smaller number of 3D points, and instead render each of them with
a larger number of pixels on the client side, this is called a {\em
splat}. A set of such splats for a given depth image, we will call a {\em proxy
model}. There are some issues to discuss in relation to this, \eg, what size and
shape of geometries to render for each 3D point, how to color them, how to
compute depth fragments and so on.

The simplest solution is to render each 3D point as a fixed geometry, for
instance a 2D disk or rectangle, with the correspondig color from the image, see
Figure~\ref{fig:2DheightmapRotated}~(c), where we have added the transformation
local to the client, which the server has not been able to provide an image for.
We will briefly describe some improvements to this. We also note that other
possibilities exist apart from this ``splat-based'' proxy model, \eg, building
and maintaining a 3D occupancy mesh, computing a distance field from which
iso-surfaces can be extracted, etc.


%-------------------------------------------------------------------------
\subsubsection{Texturing}

Our splats may result in many client window fragments, necessitating an
``intra-splat'' fragment coloring or texturing. This is not entirely straight
forward, since the client really do not know how a finitely-sized splat should
map to the server's geometry, having only a discrete set of 3D points on that
model.

A first approximation is for the client to assume that the corresponding part of
the server's model is planar in a region around the given point. If this is the
case, a local 2D texture transformation will provide a good approximation to the
intra-splat texturing to be performed on the client. For the splat centered in
$\vv_{i, j} = (x_j, y_i, z_{i, j})$, to be centered on the client's canvas at
screen coordinate $\pv_{i, j} = P_c M_c M_s^{-1} P_s^{-1}\vv_{i, j} = U\vv_{i,
j}$, the texture coordinate transformation to be used is,
\[
  T =
  \begin{pmatrix}
    \frac{1}{\text{splats}_x} & 0 \\
    0 & \frac{1}{\text{splats}_y}
  \end{pmatrix}
  \Big( \sv_x \, \, \, \sv_y \Big)^{-1}
  \begin{pmatrix} 
    \frac{\text{vpwidth}}{\text{splats}_x} & 0 \\
     0 & \frac{\text{vpheight}}{\text{splats}_y}
  \end{pmatrix}
  \cdot \text{overlap},
\]
\[
   =
  A
  \Big( \sv_x \, \, \, \sv_y \Big)^{-1}
  B
  \cdot \text{overlap},
\]
where $A$ maps the ``client's splat region'' (in $[0, 1]^2$) to the
corresponding texture area, $(\sv_{x} \, \, \, \sv_{y})^{-1}$ maps the
``client's screen space splat area'' to $[0, 1]^2$, and $B$ together with the
``overlap'' just provides a scaling factor so that ``overlap=1'' produces
non-overlapping but covering splats when $M_c=M_s$, \ie, the client does no
transformation of the proxy model.
%
% After mult by proj matrix: clip coo, range of (x, y, z) = [-w, w]^3
% After persp division: ndc [-1, 1]^3
% After viewport transf: window coordinates
% (Range [vp[0] vp[1]] x [[vp[2] vp[3]] x [0, 1] ?)
%
We compute $\sv_{x}$ and $\sv_{y}$ by evaluating proxy model positions and
performing the perspective division and transformation into window coordinates
in the vertex shader. Let proxy model positions corresponding to three corners
of a quadrilateral splat in clip coordinates be
given by
\[
  \pv =
  U { \small \begin{pmatrix} x \\ y \\ d \\ 1 \end{pmatrix} },
  \pv_{x+\Delta x} =
  U { \small \begin{pmatrix} x+\Delta x \\ y \\ d_{\Delta x} \\ 1 \end{pmatrix} }
  \text{and}\, \, \, 
  \pv_{y+\Delta y} =
  U { \small \begin{pmatrix} x \\ y+\Delta y \\ d_{\Delta y} \\ 1 \end{pmatrix} },
\]
where $d = 2\text{depthTex}(x, y) - 1$, $d_{\Delta x} =
2\text{depthTex}(x+\Delta x, y) - 1$, and $d_{\Delta y} = 2\text{depthTex}(x,
y+\Delta y) - 1$ are depths sampled from the received depth buffer and
transformed to $[-1, 1]$. By combining this with a $w$-component set to one, we
have in effect done a perspective division, so that the right-hand side vertices
are in clip space, suitable for multiplication with $U$.

We use
\begin{equation}
  \Delta x = \text{splats}_x / \text{DepthImg-width}
  \label{eq:deltaChoice}
\end{equation}
\[
  \Delta y = \text{splats}_y / \text{DepthImg-height}.
\]
\textbf{fiks de likningene over}
Note that this choice of $\Delta x$ and $\Delta y$ is not unique, we might have
chosen something larger. The values are used for looking up depth image samples,
so we should not choose something too small, our choice is exactly to look for
neighbouring depth samples. Since this calculation of $\sv_x$ and $\sv_y$ is
really a difference approximating a gradient on the geometry, we should not make
$\Delta x$ and $\Delta y$ to large either. Experiments show us
that~(\ref{eq:deltaChoice}) is really a good choice.

This then leaves us $\pv$, $\pv_{x+\Delta x}$ and $\pv_{y+\Delta y}$ in clip
coordinates, and after perspective division and viewport transformation, we get
corresponding window coordinates $\sv$, $\sv_{x+\Delta x}$ and $\sv_{y+\Delta
y}$, which we can subtract to obtain 2D vectors spanning the splat,
\[
  \sv_{\Delta x} =
  \sv_{x+\Delta x} - \sv =
    \frac{\text{width}}{2\Delta x} \left(
        \frac{\pv_{x+\Delta x}.xy}{\pv_{x+\Delta x}.w} -
        \frac{\pv.xy}{\pv.w}
    \right),
\]
and
\[
  \sv_{\Delta y} =
  \sv_{y+\Delta y} - \sv =
    \frac{\text{height}}{2\Delta y} \left(
        \frac{\pv_{y+\Delta y}.xy}{\pv_{y+\Delta y}.w} -
        \frac{\pv.xy}{\pv.w}
    \right),
\]
where we have used the ``shader notation'' to extract 2D vectors and scalars
from the 4D vectors, and $\text{width}$ and $\text{height}$ are the viewport
width and height, respectively.

Then, on the client we render a \texttt{glPoint} for each splat, with texture
coordinates $(s, t)^\prime$ and \texttt{glPointSize} set to a larger value that will
produce many fragments. Each fragment will then look up the server-rendered
image at position
\[
  \begin{pmatrix}
    s \\ t
  \end{pmatrix} +
  T 
  \begin{pmatrix}
    u \\ v
  \end{pmatrix}
\]
where $(u, v)^\prime = \texttt{gl\_PointCoord}-0.5$ are ``intra-splat texture
coordinates''. \textbf{Boer kanskje sjekke at det ikke er noen faktor 2 som har
falt ut noe sted paa veien...}

When the assumption that the geometry is locally planar does not hold, \eg, if
the splats are very large, or they originate from a rather curved or non-smooth
part of the geometry, this may look rather odd, see
Figure~\ref{fig:LargeSplatsOnCorners}.

\begin{figure}[htb]
  \centering
  \subfigure[Server-rendered]{
    \includegraphics[width=.3\linewidth]{splat1.jpg}
  }
  \subfigure[$P_c M_c = P_s M_s$]{
    \includegraphics[width=.3\linewidth]{splat2.jpg}
  }
  \subfigure[$P_c M_c \neq P_s M_s$]{
    \includegraphics[width=.3\linewidth]{splat3.jpg}
  }
  \caption{\label{fig:LargeSplatsOnCorners}
           Splats for which depths are sampled on a planar region look nice on
  exactly this region, but contorted elsewhere, notice the corner and edges of
  the cube.}
\end{figure}

The problem illustrated in Figure~\ref{fig:LargeSplatsOnCorners}, is that the
geometry is far from planar, and our simple texture coordinate transformation
will produce the wrong result for the corresponding part of involved
splats. Some ways to remedy this is, \eg, to choose smaller (and more) splats,
detect the problem and discard such splats, or introduce more complex texture
transformations. Since the proxy geometry in principle is to be short-lived, and
only a temporary geometry to be rendered before the server-rendered image can be
receieved, we have chosen a combination of the first two alternatives. Note that
implementing a more sophisticated texture coordinate transformation may actually
amount to performing the same work as for more and smaller splats. Equivalently
, using more and smaller splats may be regarded as a better texture transform
implementation.


%-------------------------------------------------------------------------
\subsubsection{Splat sizing}

Note that as soon as a given proxy model is transformed, each splat should
ideally be rendered into a number of client pixels according to the new splats
3D position. A splat transformed into view closer to the observer, should result
in more client fragments, and vice versa. To achieve this, we simply use the
vectors $\sv_{\Delta x}$ and $\sv_{\Delta y}$ from the previous section.
In addition to this, we scale the splats up a bit, typically with a factor 2, so
that they overlap. The benefit of this is that we can render rectangular
window-aligned splats on the client, without getting large uncovered areas when
interactively rotating and scaling the model quickly on the client.


%-------------------------------------------------------------------------
\subsubsection{Splat depth fragments}

For larger splats, covering many fragments, it makes sense to also compute and
use depth fragments in the client's fragment shader. This will improve the usage
of more proxy models simultaneously, since the risk of a splat with a not very
representative depth value covers another and better splat, is reduced. The
``intra-splat'' depth values can easily be fetched from the depth image, just as
the texture is looked up for color, with the same texture transformation. One
problem is that many thin clients may not support this, in WebGL, the ``frag
depth'' feature is an extension, which may not be supported everywhere.


%------------------------------------------------------------------------
\subsection{Splat set replacement algorithms}
\label{sec:proxyModelReplacement}

In this paper we mainly concern ourselves with proxy models defined as sets of
splats. Since each splat set is the product of one instance of a server-rendered
image, depth buffer and viewing parameters, it makes sense to retain more than
one such model on the client. By doing this, the client may combine them in
order to provide renderings for viewing parameters very different from the last
one received.

As soon as the client has a set of such proxy models, it will also need an
algorithm for replacing old models with new ones.  One can imagine a plethora of
{\em splat set replacement algorithms}, we have tested three approaches that all
retain a constant number of proxy models. The first algorithm is to replace the
one with a viewing direction differing the most from the newly received
model. The second simply replaces the oldest one in store. The third replaces a
proxy model $j$ if the replacement results in the following objective function
being reduced,
\[
  \text{coverage}_j = 
  \sum_{i=1, i\neq j}^n 
    \angle(\textbf{camdir}_i, \textbf{new camdir} )^2,
\]
where $\textbf{camdir}$ is the direction in which the camera was looking for the
generation of that particular proxy model.

There are some issues to consider with respect to panning and zooming that we
will not discuss here due to the limited space available.  All of these model
replacement algorithms work decently well.



%-------------------------------------------------------------------------
\subsection{Dynamic/heuristic method selection, depth compression}

Since the main purpose of the automatically generated proxy model is to
facilitate a client-rendered image while waiting for one from the server for
increased interactivity, it is important that the process of generating and
sending proxy model data from the server itself is not hold up more than
necessary. There are mainly three sources of delay (\textbf{passer aa nevne
tidligere?}) for server-rendered images to the client; high
latency, low bandwidth, and slow server-rendering itself.

In the first case, it seems prudent to have a better proxy model on the client,
that can be used for longer time and for interactivity resulting in viewing
parameters deviating more from the last received server-rendered image. In the
two other cases, it is important for the proxy model generation/transmission to
be quicker, both in order to get the proxy model to the client and keep from
delaying the server-image more than necessary.

To take care of this, we have adopted an adaptive specification of
proxy model data from the server. This involves a more light-weight image (lossy
JPG-compression with adaptive quality control) while the user is interacting
with the client, as well as a reduced resolution of the depth buffer sent from
the server. See Figure~\ref{fig:adapativeProxyModels} for examples of low- and
high-quality proxy models.

\begin{figure}[htb]
  \centering
  \subfigure[Full png image,\newline full depth buffer]{
    \includegraphics[width=.30\linewidth]{auto1.jpg}
  }
  \subfigure[Coarse jpg,\newline quality $q=0$]{
    \includegraphics[width=.30\linewidth]{auto2.jpg}
  }
  \subfigure[Auto-proxy, trun-\newline cated depth data]{
    \includegraphics[width=.30\linewidth]{auto3.jpg}
  }
  \caption{\label{fig:adapativeProxyModels} Proxy models adaptively adjusted to
           available bandwidth and server capacity. The server-rendered JPG
           image adaptively selects a quality setting based on recorded
           timings. Shown is the worst case, \texttt{quality}=0, (b) which is
           the last step before switching to ``auto proxy'' (c). The auto-proxy
           model shown displays artifacts caused both by the magenta surface
           being almost parallel to the viewing direction at the moment of proxy
           model recording, and by the non-smooth parts of the geometry
           (corners). The number of splats is set low on purpose, and the depth
           buffer size is reduced by a factor of $16^{-2} \approx 0.4\%$.}
\end{figure}



%-------------------------------------------------------------------------
\section{Results and discussion}

We have tested the algorithms discussed in the Tinia framework, which is a
programming framework for setting up and managing a client/server based
interactive OpenGL-based visualization application, see~\cite{tinia}. As client
we use Google Chrome, the code is written in standard Javascript/WebGL.
The client communicatesover tcp/ip, using either http or
websockets, with a server running as an Apache module.

The automatic proxy geometry implementation is fully invisible to the
application, meaning that all existing applications immediately will have the
feature available. We have tested the algorithm on several smaller test cases,
but also on a larger oil reservoir viewer, FRView, developed in the CloudViz
project, see~\cite{cloudviz}.

This viewer utilizes several GLSL shaders to render reservoir cells and
boundaries ({\em corner point grids}), tubular wells etc., and operates in
general on a geometric model that is not trivial to reduce in complexity. The
model is typically also very large, meaning that rendering the full model on a
thin client is prohibitive. With the automatic proxy geometry, we can obtain
interactive frame rates with a limited connection from a very lightweight client
to the server. For a comparison of a server-rendered image and a client-rendered
proxy model that is slightly rotated on the client, see Figure~\ref{fig:FRView}.


%-------------------------------------------------------------------------
\section{Conclusion and future work}

The single most attractive feature of such an automatic proxy geometry as
described, is exactly the automated generation. It means that problems with
downscaling, sending and rendering existing geometries is bypassed
altogether. The Tinia framework with which we have demonstrated this, is a
framework for setting up and managing a client/server based interactive OpenGL
based visualization application. The automatic proxy geometry implementation is
fully invisible to the application, meaning that all existing applications
immediately will have the feature available.

There are several directions in which we would like to follow up and improve
this concept,
\begin{itemize}
\item \textbf{Proxy model replacement algorithms} The goal is to obtain a good view with
all relevant viewing parameters on the client, with the help of a minimal set of
proxy models.
\item \textbf{Grid-based proxy geometry} Instead of a set of ``splats'', one can
envision a spatially partioned grid, for instance containing a distance field,
with the geometry as an iso-surface.
\end{itemize}




%-------------------------------------------------------------------------
\section{Midlertidige notater}

\begin{itemize}

\item We restrict ourselves to discuss ``splat sets'' in this paper. (Nevne der det
tas frem andre alternativer)

\item
Husk aa faa med det viktige i at vi faar oekt serverkapasiteten til aa
serve flere klienter ogsaa!

\item
``server-image'' i steden for ``server-rendered image'' for aa spare plass?

\item received stavekontroll

\item Hvor passer det aa faa inn 1) bilde og 2) tekst om FRView?

\item Maa ta et lite soek paa prior art innen omraadet

\item problem med shading/shadows ++ i forb. med ikke deferred shading/normal map

\item About our test case: corners, smooth surfaces, texturing for which artifacts are easy to
spot. What it does lack is self-occluding parts. The FRView rservoir model that
we have tested on does contain some of this.

\item Burde vi vise chemco?

\item Sjekk konsistens ved bruk av kombinasjoner som ``server rendered'' og
``server-rendered'' etc.

\item Referanser? Prior work?

\end{itemize}




%-------------------------------------------------------------------------

%\bibliographystyle{eg-alpha}
\bibliographystyle{eg-alpha-doi}

\bibliography{egbibsample}

%-------------------------------------------------------------------------

\end{document}
